《机器学习实战》读书笔记系列(二):K-近邻算法

一、	认识
K-近邻算法是最简单的分类算法,采用测量不同特征值之间的距离方法进行分类
也叫做 KNN算法

二、算法优缺点
优点 : 精度高、对异常值不敏感、无数据输入嘉定
缺点 :  计算复杂度高、空间复杂度高, 分类阶段很慢且需要大量的内存，特征和缺失数据需要额外处理
适用数据范围 : 数值型和标称型

二、	算法工作原理
所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居）， 这K个实例的多数属于某个类，就把该输入实例分类到这个类中
「通常k是不大于20的整数」

三、	样例
用KNN算法对未知电影进行分类,判断电影是爱情片还是动作片

 
KNN算法首先要计算未知电影与样本集中其他电影的距离
 
按照距离排序,假定k=3,那么前三个样本电影都是爱情片,因此我们判定未知电影也是爱情片

四、k-近邻算法的一般流程
收集数据 : 任何方法
准备数据 : 距离计算所需要的数值,最好是结构化的数据格式
分析数据 : 可以使用任何方法
训练算法 : 此步骤不适用于k-近邻算法
测试算法 : 计算错误率
使用算法 : 首先需要输入样本数据和结构化的输出结果,然后运行k-近邻算法判定shares护具分别属于哪个分类,最后应用对计算出的分类执行后续的处理

五、	Python 实操(本书所有源代码都可以在网站上下载: https://www.manning.com/books/machine-learning-in-action

对未知类别属性的数据集中的每个点依次执行以下操作：
（1）	计算已知类别数据集中的点与当前点之间的距离
（2）	按照距离递增次序排序
（3）	选取与当前点距离最小的k个点
（4）	确定前k个点所在类别的出现频率
（5）	返回前k个点出现频率最高的类别作为当前点的预测分类

